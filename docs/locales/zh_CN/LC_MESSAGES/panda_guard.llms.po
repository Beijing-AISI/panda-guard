# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2024, Floyed Shen, etc.
# This file is distributed under the same license as the Panda-Guard
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Panda-Guard \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-05-12 08:42+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/panda_guard.llms.rst:2
msgid "panda\\_guard.llms package"
msgstr ""

#: ../../source/panda_guard.llms.rst:5
msgid "Submodules"
msgstr ""

#: ../../source/panda_guard.llms.rst:8
msgid "panda\\_guard.llms.base module"
msgstr ""

#: of panda_guard.llms.base.BaseLLM:1 panda_guard.llms.base.BaseLLMConfig:1
msgid "Bases: :py:class:`~abc.ABC`"
msgstr ""

#: of panda_guard.llms.base.BaseLLM:1
msgid "Abstract base class for LLM."
msgstr ""

#: ../../source/panda_guard.llms.rst
msgid "Parameters"
msgstr ""

#: of panda_guard.llms.base.BaseLLM:3
msgid "Configuration object for LLM.  LLM的配置对象"
msgstr ""

#: of panda_guard.llms.base.BaseLLM.avg_tokens:1
msgid "Get the average number of tokens per request."
msgstr ""

#: ../../source/panda_guard.llms.rst
msgid "Returns"
msgstr ""

#: of panda_guard.llms.base.BaseLLM.avg_tokens:3
msgid "Average number of tokens.  返回每次请求的词汇平均值"
msgstr ""

#: of panda_guard.llms.base.BaseLLM.batch_generate:1
msgid "Generate responses for a batch of messages concurrently."
msgstr ""

#: of panda_guard.llms.base.BaseLLM.batch_generate:3
msgid "List of batches of messages.  消息的批量列表"
msgstr ""

#: of panda_guard.llms.base.BaseLLM.batch_generate:4
#: panda_guard.llms.base.BaseLLM.continual_generate:4
#: panda_guard.llms.base.BaseLLM.evaluate_log_likelihood:4
#: panda_guard.llms.base.BaseLLM.generate:4
#: panda_guard.llms.claude.ClaudeLLM.continual_generate:4
#: panda_guard.llms.gemini.GeminiLLM.continual_generate:4
#: panda_guard.llms.hf.HuggingFaceLLM.continual_generate:4
#: panda_guard.llms.oai.OpenAiChatLLM.continual_generate:4
#: panda_guard.llms.oai.OpenAiLLM.continual_generate:4
#: panda_guard.llms.vllm.VLLMLLM.continual_generate:4
msgid "Configuration for generation.  生成配置"
msgstr ""

#: of panda_guard.llms.base.BaseLLM.batch_generate:5
msgid "List of generated responses.  返回生成的应答列表"
msgstr ""

#: of panda_guard.llms.base.BaseLLM.continual_generate:1
#: panda_guard.llms.hf.HuggingFaceLLM.continual_generate:1
#: panda_guard.llms.oai.OpenAiChatLLM.continual_generate:1
#: panda_guard.llms.oai.OpenAiLLM.continual_generate:1
msgid "Remove EOS token in formatted prompt. Manually add generation prompt."
msgstr ""

#: of panda_guard.llms.base.BaseLLM.continual_generate:3
#: panda_guard.llms.base.BaseLLM.generate:3
#: panda_guard.llms.claude.ClaudeLLM.continual_generate:3
#: panda_guard.llms.gemini.GeminiLLM.continual_generate:3
#: panda_guard.llms.hf.HuggingFaceLLM.continual_generate:3
#: panda_guard.llms.oai.OpenAiChatLLM.continual_generate:3
#: panda_guard.llms.oai.OpenAiLLM.continual_generate:3
#: panda_guard.llms.vllm.VLLMLLM.continual_generate:3
msgid "List of messages for input.  输入的消息列表"
msgstr ""

#: of panda_guard.llms.base.BaseLLM.continual_generate:5
#: panda_guard.llms.base.BaseLLM.generate:5
#: panda_guard.llms.hf.HuggingFaceLLM.continual_generate:5
#: panda_guard.llms.oai.OpenAiChatLLM.continual_generate:5
#: panda_guard.llms.oai.OpenAiLLM.continual_generate:5
#: panda_guard.llms.vllm.VLLMLLM.continual_generate:5
msgid "Generated response or responses with log probabilities.  返回生成的应答或启用百分比的应答"
msgstr ""

#: of panda_guard.llms.base.BaseLLM.evaluate_log_likelihood:1
msgid "Abstract method for evaluating log likelihood of messages."
msgstr ""

#: of panda_guard.llms.base.BaseLLM.evaluate_log_likelihood:3
msgid "List of messages to evaluate.  需要评估的消息列表"
msgstr ""

#: of panda_guard.llms.base.BaseLLM.evaluate_log_likelihood:5
msgid "Determine whether returned logprobs has grad"
msgstr ""

#: of panda_guard.llms.base.BaseLLM.evaluate_log_likelihood:6
msgid "List of log likelihoods.  返回的百分比列表"
msgstr ""

#: of panda_guard.llms.base.BaseLLM.generate:1
msgid "Abstract method for generating response from LLM."
msgstr ""

#: of panda_guard.llms.base.BaseLLM.reset:1
msgid "Reset the token counts and the number of requests."
msgstr ""

#: of panda_guard.llms.base.BaseLLM.reset:3
msgid "重置词汇计数和请求次数"
msgstr ""

#: of panda_guard.llms.base.BaseLLM.total_tokens:1
msgid "Get the total number of tokens used."
msgstr ""

#: of panda_guard.llms.base.BaseLLM.total_tokens:3
msgid "Total number of tokens.  返回的词汇总数"
msgstr ""

#: of panda_guard.llms.base.BaseLLM.update:1
msgid "Update the token counts and number of requests."
msgstr ""

#: of panda_guard.llms.base.BaseLLM.update:3
msgid "Number of tokens in prompt.  提示中的词汇数"
msgstr ""

#: of panda_guard.llms.base.BaseLLM.update:4
msgid "Number of tokens in completion.  完成中的词汇数"
msgstr ""

#: of panda_guard.llms.base.BaseLLM.update:5
msgid "Number of requests made.  请求次数"
msgstr ""

#: of panda_guard.llms.base.BaseLLMConfig:1
msgid "Base configuration for LLM."
msgstr ""

#: of panda_guard.llms.base.BaseLLMConfig:3
msgid "Type of the LLM.  LLM的类型"
msgstr ""

#: of panda_guard.llms.base.BaseLLMConfig:4
#: panda_guard.llms.claude.ClaudeLLMConfig:4
#: panda_guard.llms.gemini.GeminiLLMConfig:4
#: panda_guard.llms.oai.OpenAiChatLLMConfig:4
#: panda_guard.llms.oai.OpenAiLLMConfig:4
msgid "Name of the model.  模型的名称"
msgstr ""

#: of panda_guard.llms.base.LLMGenerateConfig:1
msgid "Bases: :py:class:`object`"
msgstr ""

#: of panda_guard.llms.base.LLMGenerateConfig:1
msgid "Configuration for LLM generation."
msgstr ""

#: of panda_guard.llms.base.LLMGenerateConfig:3
msgid "Maximum number of tokens to generate.  最大生成的词汇数量"
msgstr ""

#: of panda_guard.llms.base.LLMGenerateConfig:4
msgid "Temperature for sampling randomness.  用于样本随机的温度参数"
msgstr ""

#: of panda_guard.llms.base.LLMGenerateConfig:5
msgid "Whether to return log probabilities.  是否返回logprobs"
msgstr ""

#: of panda_guard.llms.base.LLMGenerateConfig:6
msgid "Seed for reproducibility.  用于可重复的种子"
msgstr ""

#: of panda_guard.llms.base.LLMGenerateConfig:7
msgid "Whether to use streaming generation.  是否使用流式生成"
msgstr ""

#: ../../source/panda_guard.llms.rst:16
msgid "panda\\_guard.llms.claude module"
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLM:1 panda_guard.llms.gemini.GeminiLLM:1
#: panda_guard.llms.hf.HuggingFaceLLM:1 panda_guard.llms.oai.OpenAiChatLLM:1
#: panda_guard.llms.oai.OpenAiLLM:1 panda_guard.llms.vllm.VLLMLLM:1
msgid "Bases: :py:class:`~panda_guard.llms.base.BaseLLM`"
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLM:1
msgid "Claude LLM Implementation."
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLM:3
msgid "Configuration for Claude LLM.  用于Claude LLM的配置"
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLM.continual_generate:1
#: panda_guard.llms.gemini.GeminiLLM.continual_generate:1
msgid "Generate continuation for the last message."
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLM.continual_generate:5
#: panda_guard.llms.gemini.GeminiLLM.continual_generate:5
msgid "Generated response.  返回生成的应答"
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLM.evaluate_log_likelihood:1
#: panda_guard.llms.gemini.GeminiLLM.evaluate_log_likelihood:1
#: panda_guard.llms.hf.HuggingFaceLLM.evaluate_log_likelihood:1
#: panda_guard.llms.oai.OpenAiChatLLM.evaluate_log_likelihood:1
#: panda_guard.llms.oai.OpenAiLLM.evaluate_log_likelihood:1
#: panda_guard.llms.vllm.VLLMLLM.evaluate_log_likelihood:1
msgid "Evaluate the log likelihood of the given messages."
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLM.evaluate_log_likelihood:3
#: panda_guard.llms.gemini.GeminiLLM.evaluate_log_likelihood:3
#: panda_guard.llms.hf.HuggingFaceLLM.evaluate_log_likelihood:3
#: panda_guard.llms.oai.OpenAiChatLLM.evaluate_log_likelihood:3
#: panda_guard.llms.oai.OpenAiLLM.evaluate_log_likelihood:3
#: panda_guard.llms.vllm.VLLMLLM.evaluate_log_likelihood:3
msgid "List of messages for evaluation.  需要评估的消息列表"
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLM.evaluate_log_likelihood:4
#: panda_guard.llms.claude.ClaudeLLM.generate:4
#: panda_guard.llms.gemini.GeminiLLM.evaluate_log_likelihood:4
#: panda_guard.llms.gemini.GeminiLLM.generate:4
#: panda_guard.llms.hf.HuggingFaceLLM.batch_generate:4
#: panda_guard.llms.hf.HuggingFaceLLM.evaluate_log_likelihood:4
#: panda_guard.llms.hf.HuggingFaceLLM.generate:4
#: panda_guard.llms.oai.OpenAiChatLLM.evaluate_log_likelihood:4
#: panda_guard.llms.oai.OpenAiChatLLM.generate:4
#: panda_guard.llms.oai.OpenAiLLM.evaluate_log_likelihood:4
#: panda_guard.llms.oai.OpenAiLLM.generate:4
#: panda_guard.llms.vllm.VLLMLLM.batch_generate:4
#: panda_guard.llms.vllm.VLLMLLM.evaluate_log_likelihood:4
#: panda_guard.llms.vllm.VLLMLLM.generate:4
msgid "Configuration for LLM generation.  生成配置"
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLM.evaluate_log_likelihood:5
#: panda_guard.llms.gemini.GeminiLLM.evaluate_log_likelihood:5
msgid "Whether to compute gradients (not supported for API models)"
msgstr ""

#: ../../source/panda_guard.llms.rst
msgid "Raises"
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLM.evaluate_log_likelihood:6
msgid "Claude API does not support log likelihood evaluation."
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLM.generate:1
msgid "Generate a response for a given input using Anthropic Claude API."
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLM.generate:3
#: panda_guard.llms.gemini.GeminiLLM.generate:3
#: panda_guard.llms.hf.HuggingFaceLLM.generate:3
#: panda_guard.llms.oai.OpenAiChatLLM.generate:3
#: panda_guard.llms.oai.OpenAiLLM.generate:3
#: panda_guard.llms.vllm.VLLMLLM.generate:3
msgid "List of input messages.  输入的消息列表"
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLM.generate:5
#: panda_guard.llms.gemini.GeminiLLM.generate:5
#: panda_guard.llms.hf.HuggingFaceLLM.generate:5
#: panda_guard.llms.vllm.VLLMLLM.generate:5
msgid ""
"Generated response, stream generator, or response with logprobs.  "
"返回生成的应答、流式生成器或启用logprobs的应答"
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLMConfig:1
#: panda_guard.llms.gemini.GeminiLLMConfig:1
#: panda_guard.llms.hf.HuggingFaceLLMConfig:1
#: panda_guard.llms.oai.OpenAiChatLLMConfig:1
#: panda_guard.llms.oai.OpenAiLLMConfig:1 panda_guard.llms.vllm.VLLMLLMConfig:1
msgid "Bases: :py:class:`~panda_guard.llms.base.BaseLLMConfig`"
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLMConfig:1
msgid "Claude LLM Configuration."
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLMConfig:3
msgid "Type of LLM, default is \"ClaudeLLM\".  LLM的类型，默认值为 \"ClaudeLLM\""
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLMConfig:5
msgid "API key for accessing Anthropic.  访问Anthropic的API密钥"
msgstr ""

#: of panda_guard.llms.claude.ClaudeLLMConfig:6
msgid ""
"Maximum tokens to sample, overrides max_n_tokens if provided. "
"最大采样词汇数，如果提供则覆盖max_n_tokens"
msgstr ""

#: ../../source/panda_guard.llms.rst:24
msgid "panda\\_guard.llms.gemini module"
msgstr ""

#: of panda_guard.llms.gemini.GeminiLLM:1
msgid "Gemini LLM Implementation."
msgstr ""

#: of panda_guard.llms.gemini.GeminiLLM:3
msgid "Configuration for Gemini LLM.  用于Gemini LLM的配置"
msgstr ""

#: of panda_guard.llms.gemini.GeminiLLM.evaluate_log_likelihood:6
msgid "Gemini API does not support log likelihood evaluation."
msgstr ""

#: of panda_guard.llms.gemini.GeminiLLM.generate:1
msgid "Generate a response for a given input using Google Gemini API."
msgstr ""

#: of panda_guard.llms.gemini.GeminiLLMConfig:1
msgid "Gemini LLM Configuration."
msgstr ""

#: of panda_guard.llms.gemini.GeminiLLMConfig:3
msgid "Type of LLM, default is \"GeminiLLM\".  LLM的类型，默认值为 \"GeminiLLM\""
msgstr ""

#: of panda_guard.llms.gemini.GeminiLLMConfig:5
msgid "API key for accessing Google AI.  访问Google AI的API密钥"
msgstr ""

#: of panda_guard.llms.gemini.GeminiLLMConfig:6
msgid "Custom safety settings for the model. 自定义安全设置"
msgstr ""

#: ../../source/panda_guard.llms.rst:32
msgid "panda\\_guard.llms.hf module"
msgstr ""

#: of panda_guard.llms.hf.HuggingFaceLLM:1
msgid "Hugging Face Language Model Implementation."
msgstr ""

#: of panda_guard.llms.hf.HuggingFaceLLM:3
msgid "Configuration for Hugging Face LLM.  用于模型配置"
msgstr ""

#: of panda_guard.llms.hf.HuggingFaceLLM.batch_generate:1
msgid "Generate responses for a batch of messages in a single call."
msgstr ""

#: of panda_guard.llms.hf.HuggingFaceLLM.batch_generate:3
#: panda_guard.llms.vllm.VLLMLLM.batch_generate:3
msgid "List of batches of messages.  批量生成的消息列表"
msgstr ""

#: of panda_guard.llms.hf.HuggingFaceLLM.batch_generate:5
#: panda_guard.llms.vllm.VLLMLLM.batch_generate:5
msgid "List of generated responses for each batch.  返回每个批量的生成应答列表"
msgstr ""

#: of panda_guard.llms.hf.HuggingFaceLLM.evaluate_log_likelihood:5
msgid "logprobs have grad"
msgstr ""

#: of panda_guard.llms.hf.HuggingFaceLLM.evaluate_log_likelihood:6
#: panda_guard.llms.oai.OpenAiLLM.evaluate_log_likelihood:5
#: panda_guard.llms.vllm.VLLMLLM.evaluate_log_likelihood:6
msgid "List of log likelihood values.  返回的log likelihood值列表"
msgstr ""

#: of panda_guard.llms.hf.HuggingFaceLLM.generate:1
msgid "Generate a response for a given input using Hugging Face model."
msgstr ""

#: of panda_guard.llms.hf.HuggingFaceLLMConfig:1
msgid "Hugging Face LLM Configuration."
msgstr ""

#: of panda_guard.llms.hf.HuggingFaceLLMConfig:3
msgid ""
"Type of LLM, default is \"HuggingFaceLLM\".  LLM的类型，默认值为 "
"\"HuggingFaceLLM\""
msgstr ""

#: of panda_guard.llms.hf.HuggingFaceLLMConfig:4
msgid "Name of the model or model instance.  模型的名称或模型实例"
msgstr ""

#: of panda_guard.llms.hf.HuggingFaceLLMConfig:5
msgid "Device mapping for model deployment.  用于模型部署的设备对应表"
msgstr ""

#: ../../source/panda_guard.llms.rst:40
msgid "panda\\_guard.llms.llm\\_registry module"
msgstr ""

#: ../../source/panda_guard.llms.rst:48
msgid "panda\\_guard.llms.oai module"
msgstr ""

#: of panda_guard.llms.oai.OpenAiChatLLM:1
msgid "OpenAI Chat LLM Implementation."
msgstr ""

#: of panda_guard.llms.oai.OpenAiChatLLM:3
msgid "Configuration for OpenAI Chat LLM.  用于OpenAI小谱LLM的配置"
msgstr ""

#: of panda_guard.llms.oai.OpenAiChatLLM.evaluate_log_likelihood:5
msgid ""
"OpenAI Chat does not support log likelihood evaluation.  这个LLM属性不支持log "
"likelihood评估"
msgstr ""

#: of panda_guard.llms.oai.OpenAiChatLLM.generate:1
msgid "Generate a response for a given input using OpenAI Chat API."
msgstr ""

#: of panda_guard.llms.oai.OpenAiChatLLM.generate:5
#: panda_guard.llms.oai.OpenAiLLM.generate:5
msgid ""
"Generated response or response with logprobs or stream generator.  "
"返回生成的应答、启用logprobs的应答或流式生成器"
msgstr ""

#: of panda_guard.llms.oai.OpenAiChatLLMConfig:1
msgid "OpenAI Chat LLM Configuration."
msgstr ""

#: of panda_guard.llms.oai.OpenAiChatLLMConfig:3
msgid "Type of LLM, default is \"OpenAiChatLLM\".  LLM的类型，默认值为 \"OpenAiChatLLM\""
msgstr ""

#: of panda_guard.llms.oai.OpenAiChatLLMConfig:5
#: panda_guard.llms.oai.OpenAiLLMConfig:5
msgid "Base URL for the OpenAI API.  OpenAI API的基础URL"
msgstr ""

#: of panda_guard.llms.oai.OpenAiChatLLMConfig:6
#: panda_guard.llms.oai.OpenAiLLMConfig:6
msgid "API key for accessing OpenAI.  访问OpenAI的API密钥"
msgstr ""

#: of panda_guard.llms.oai.OpenAiLLM:1
msgid "OpenAI LLM Implementation."
msgstr ""

#: of panda_guard.llms.oai.OpenAiLLM:3
msgid "Configuration for OpenAI LLM.  用于OpenAI LLM的配置"
msgstr ""

#: of panda_guard.llms.oai.OpenAiLLM.generate:1
msgid "Generate a response for a given input using OpenAI API."
msgstr ""

#: of panda_guard.llms.oai.OpenAiLLMConfig:1
msgid "OpenAI LLM Configuration."
msgstr ""

#: of panda_guard.llms.oai.OpenAiLLMConfig:3
msgid "Type of LLM, default is \"OpenAiLLM\".  LLM的类型，默认值为 \"OpenAiLLM\""
msgstr ""

#: ../../source/panda_guard.llms.rst:56
msgid "panda\\_guard.llms.vllm module"
msgstr ""

#: of panda_guard.llms.vllm.VLLMLLM:1
msgid "VLLM LLM Implementation for high-performance inference."
msgstr ""

#: of panda_guard.llms.vllm.VLLMLLM:3
msgid "Configuration for VLLM LLM.  用于VLLM LLM的配置"
msgstr ""

#: of panda_guard.llms.vllm.VLLMLLM.batch_generate:1
msgid ""
"Generate responses for a batch of messages in one go using VLLM's "
"batching capabilities."
msgstr ""

#: of panda_guard.llms.vllm.VLLMLLM.continual_generate:1
msgid "Generate continuation for the existing conversation."
msgstr ""

#: of panda_guard.llms.vllm.VLLMLLM.evaluate_log_likelihood:5
msgid "Whether grad information is needed (not supported in VLLM)"
msgstr ""

#: of panda_guard.llms.vllm.VLLMLLM.generate:1
msgid "Generate a response using VLLM."
msgstr ""

#: of panda_guard.llms.vllm.VLLMLLMConfig:1
msgid "VLLM LLM Configuration."
msgstr ""

#: of panda_guard.llms.vllm.VLLMLLMConfig:3
msgid "Type of LLM, default is \"VLLMLLM\".  LLM的类型，默认值为 \"VLLMLLM\""
msgstr ""

#: of panda_guard.llms.vllm.VLLMLLMConfig:4
msgid "Name or path of the model.  模型的名称或路径"
msgstr ""

#: of panda_guard.llms.vllm.VLLMLLMConfig:5
msgid "Number of GPUs to use for tensor parallelism.  用于张量并行的GPU数量"
msgstr ""

#: of panda_guard.llms.vllm.VLLMLLMConfig:6
msgid "Fraction of GPU memory to use. 使用GPU内存的比例"
msgstr ""

#: of panda_guard.llms.vllm.VLLMLLMConfig:7
msgid "Maximum sequence length. 最大序列长度"
msgstr ""

#: of panda_guard.llms.vllm.VLLMLLMConfig:8
msgid "Quantization method to use. 量化方法"
msgstr ""

#: of panda_guard.llms.vllm.VLLMLLMConfig:9
msgid "Whether to trust remote code. 是否信任远程代码"
msgstr ""

#: ../../source/panda_guard.llms.rst:64
msgid "Module contents"
msgstr ""


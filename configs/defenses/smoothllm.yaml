batch_inference: true
defender_cls: SmoothLLMDefender
num_perturbations: 3
perturbation_ratio: 0.1
perturbation_type: swap
target_llm_config:
  llm_type: OpenAiLLM
  model_name: meta-llama/Meta-Llama-3.1-70B-Instruct
target_llm_gen_config:
  logprobs: false
  max_n_tokens: 4096
  seed: null
  temperature: 1.0
